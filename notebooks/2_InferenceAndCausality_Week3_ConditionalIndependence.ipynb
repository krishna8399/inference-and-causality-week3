{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7871310d",
   "metadata": {},
   "source": [
    "# Conditional Independence\n",
    "**Hands‑on Notebook**\n",
    "\n",
    "\n",
    "**In this notebook**\n",
    "Explore **conditional independence** in chain / fork / collider.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca1293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab55b5",
   "metadata": {},
   "source": [
    "## Conditional Independence in **Chain / Fork / Collider**\n",
    "\n",
    "In this section we simulate three fundamental causal structures (often called the *building blocks* of causal graphs)  \n",
    "to explore how **conditional independence** behaves in each.\n",
    "\n",
    "Reminder:\n",
    "### Marginal vs Conditional Correlation\n",
    "\n",
    "- **Marginal correlation** measures how two variables vary together *overall*, without taking any other variables into account.  \n",
    "  → Example: the raw relationship between Smoking and Cancer in the population.\n",
    "\n",
    "- **Conditional correlation** measures how two variables relate *after we fix or control for* a third variable.  \n",
    "  → Example: the relationship between Smoking and Cancer **within each level of Tar exposure**.\n",
    "\n",
    "**Key idea:**  \n",
    "If two variables are correlated marginally but not conditionally, it means a third variable (a mediator or confounder) explains their association.  \n",
    "Conversely, if they are independent marginally but correlated conditionally, conditioning has **opened a path** (as in collider bias).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Chain: A → B → C\n",
    "**Interpretation:**  \n",
    "B, \"the mediator\" transmits information or influence from A to C.  \n",
    "- *Example:* Smoking → Tar in lungs → Cancer.  \n",
    "- A and C are correlated because information “flows” through B.  \n",
    "- **If we condition on B**, we block that path — A and C become (approximately) independent.\n",
    "\n",
    "**Expectation:**  \n",
    "- Marginal correlation: high (A and C move together).  \n",
    "- Conditional correlation given B: ≈ 0 (path blocked).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Fork (Confounding): A ← U → C\n",
    "**Interpretation:**  \n",
    "U is a *common cause* (confounder) of both A and C.  \n",
    "- *Example:* Genetic predisposition → Smoking and Cancer.  \n",
    "- A and C appear correlated, but only because of U.  \n",
    "- **If we condition on U**, we remove that shared cause and eliminate the spurious correlation.\n",
    "\n",
    "**Expectation:**  \n",
    "- Marginal correlation: high (U induces a false link).  \n",
    "- Conditional correlation given U: ≈ 0 (confounding removed).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Collider: A → B ← C\n",
    "**Interpretation:**  \n",
    "B is a *common effect* (collider) of A and C.  \n",
    "- *Example:*  \n",
    "  - A = Smoking  \n",
    "  - C = Air pollution  \n",
    "  - B = Hospital admission (caused by either).  \n",
    "- Normally, A and C are independent.  \n",
    "- **If we condition on B** (or any descendant of B), we *create* a correlation between A and C —  \n",
    "  this is known as **collider bias** or **selection bias**.\n",
    "\n",
    "**Expectation:**  \n",
    "- Marginal correlation: near 0 (A, C independent).  \n",
    "- Conditional correlation given B: strong (conditioning opens the path).\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "> Correlation alone can mislead: depending on the graph, conditioning can remove, reveal, or even **fabricate** relationships.\n",
    ">\n",
    "> Understanding which paths are open or closed (via **d-separation**) is central to causal inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349a779",
   "metadata": {},
   "source": [
    "\n",
    "### What the following block of code does\n",
    "- Each function (`sim_chain`, `sim_fork`, `sim_collider`) simulates random data following these causal relationships.  \n",
    "- We compute:\n",
    "  - **Marginal correlation**: `corr(A, C)`  \n",
    "  - **Conditional correlation**: `corr(A, C | middle node)` using simple binning on the conditioning variable.\n",
    "- This shows how *conditioning* can either **block** or **create** associations depending on the graph structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "069adc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain: corr(A,C)  (marginal) = 0.5801684286913067\n",
      "Fork:  corr(A,C)  (marginal) = 0.4971395078854403\n",
      "Collider: corr(A,C) (marginal) = -0.010648989688450418\n",
      "\n",
      "Conditioning (approx via binning):\n",
      "Chain: corr(A,C | B) ≈ 0.04719708880720996\n",
      "Fork:  corr(A,C | U) ≈ 0.03878851215357193\n",
      "Collider: corr(A,C | B) ≈ -0.4745972035238439\n"
     ]
    }
   ],
   "source": [
    "def sim_chain(N=50_000, seed=1):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    A = rng.normal(0,1,N)\n",
    "    B = A + rng.normal(0,1,N)\n",
    "    C = B + rng.normal(0,1,N)\n",
    "    return pd.DataFrame(dict(A=A,B=B,C=C))\n",
    "\n",
    "def sim_fork(N=50_000, seed=2):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    U = rng.normal(0,1,N)\n",
    "    A = U + rng.normal(0,1,N)\n",
    "    C = U + rng.normal(0,1,N)\n",
    "    return pd.DataFrame(dict(U=U,A=A,C=C))\n",
    "\n",
    "def sim_collider(N=50_000, seed=3):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    A = rng.normal(0,1,N)\n",
    "    C = rng.normal(0,1,N)\n",
    "    B = A + C + rng.normal(0,1,N)  # collider\n",
    "    return pd.DataFrame(dict(A=A,B=B,C=C))\n",
    "\n",
    "def corr(x,y,df):\n",
    "    return np.corrcoef(df[x], df[y])[0,1]\n",
    "\n",
    "chain = sim_chain()\n",
    "fork = sim_fork()\n",
    "coll = sim_collider()\n",
    "\n",
    "print(\"Chain: corr(A,C)  (marginal) =\", corr(\"A\",\"C\", chain))\n",
    "print(\"Fork:  corr(A,C)  (marginal) =\", corr(\"A\",\"C\", fork))\n",
    "print(\"Collider: corr(A,C) (marginal) =\", corr(\"A\",\"C\", coll))\n",
    "\n",
    "# Conditioning effects\n",
    "def partial_corr_xy_given_z(x,y,z,df, bins=10):\n",
    "    # Approximate partial correlation by binning on z (simple classroom-friendly approach).\n",
    "    df2 = df.copy()\n",
    "    df2[\"_zb\"] = pd.qcut(df2[z], q=bins, duplicates=\"drop\")\n",
    "    vals = []\n",
    "    for _,grp in df2.groupby(\"_zb\", observed=True):\n",
    "        if len(grp)>5:\n",
    "            vals.append(np.corrcoef(grp[x], grp[y])[0,1])\n",
    "    return np.nanmean(vals)\n",
    "\n",
    "print(\"\\nConditioning (approx via binning):\")\n",
    "print(\"Chain: corr(A,C | B) ≈\", partial_corr_xy_given_z(\"A\",\"C\",\"B\", chain))\n",
    "print(\"Fork:  corr(A,C | U) ≈\", partial_corr_xy_given_z(\"A\",\"C\",\"U\", fork))\n",
    "print(\"Collider: corr(A,C | B) ≈\", partial_corr_xy_given_z(\"A\",\"C\",\"B\", coll))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac85f572",
   "metadata": {},
   "source": [
    "### Interpretation of Results\n",
    "\n",
    "| Structure | Marginal Corr(A, C) | Conditional Corr(A, C \\| Z) | What it shows |\n",
    "|------------|--------------------:|-----------------------------:|----------------|\n",
    "| **Chain** | 0.58 | 0.05 | Conditioning on the mediator **B** blocks the flow from A → B → C. |\n",
    "| **Fork** | 0.50 | 0.04 | Conditioning on the confounder **U** removes the common-cause association. |\n",
    "| **Collider** | −0.01 | −0.47 | Conditioning on **B** (a common effect) creates a spurious link — classic *collider bias*. |\n",
    "\n",
    "**Summary:**  \n",
    "- **Chain & Fork:** conditioning *reduces* correlation (closes the path).  \n",
    "- **Collider:** conditioning *induces* correlation (opens a blocked path).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3d31b",
   "metadata": {},
   "source": [
    "## Excersice:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1cfad8",
   "metadata": {},
   "source": [
    " **Collider bias:** In section B, filter to the top 10% of `B` values in the collider model and compute `corr(A,C)` there.  \n",
    "   - Why does this selection amplify the association?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61abb8e5-7ee9-49d5-96f9-49e1780a1f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collider model:\n",
      "  Marginal corr(A, C):        -0.011\n",
      "  Corr(A, C) in top 10% of B: -0.377\n"
     ]
    }
   ],
   "source": [
    "# Collider model (reusing the provided function)\n",
    "def sim_collider(N=50_000, seed=3):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    A = rng.normal(0,1,N)\n",
    "    C = rng.normal(0,1,N)\n",
    "    B = A + C + rng.normal(0,1,N)  # collider\n",
    "    return pd.DataFrame(dict(A=A,B=B,C=C))\n",
    "\n",
    "coll = sim_collider()\n",
    "\n",
    "# 1️⃣ Marginal correlation between A and C (no conditioning)\n",
    "corr_marginal = np.corrcoef(coll[\"A\"], coll[\"C\"])[0,1]\n",
    "\n",
    "# 2️⃣ Filter to top 10% of B (conditioning by selection)\n",
    "threshold = np.percentile(coll[\"B\"], 90)\n",
    "coll_top10 = coll[coll[\"B\"] >= threshold]\n",
    "\n",
    "# 3️⃣ Correlation between A and C *after* selecting high B (collider bias)\n",
    "corr_conditioned = np.corrcoef(coll_top10[\"A\"], coll_top10[\"C\"])[0,1]\n",
    "\n",
    "print(\"Collider model:\")\n",
    "print(f\"  Marginal corr(A, C):        {corr_marginal:.3f}\")\n",
    "print(f\"  Corr(A, C) in top 10% of B: {corr_conditioned:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece88481-72a3-4f59-bbc5-462711b67746",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Explanation — Collider Bias:**\n",
    "\n",
    "In the collider structure A → B ← C, variables A and C are *independent* overall,\n",
    "so their marginal correlation is near zero.\n",
    "\n",
    "However, when we **condition on B** (or equivalently, select only high-B cases, such as the top 10%),\n",
    "we create a *spurious negative association* between A and C.\n",
    "\n",
    "Intuitively, if both A and C contribute to B, then among people with high B values,\n",
    "those with higher A tend to have lower C (and vice versa) to keep B in the same range.\n",
    "\n",
    "This artificial dependence is called **collider bias** or **selection bias** —\n",
    "it shows that conditioning on an outcome (or its descendant) can open a path between otherwise independent causes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
